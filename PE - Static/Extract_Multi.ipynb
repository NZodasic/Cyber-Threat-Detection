{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M1TLd6fTZxZY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pefile\n",
        "import math\n",
        "import csv\n",
        "import hashlib\n",
        "from collections import Counter, defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c_D8asxYZyPv"
      },
      "outputs": [],
      "source": [
        "KNOWN_SECTIONS = [\n",
        "    \".text\", \".rdata\", \".data\", \".idata\", \".edata\",\n",
        "    \".pdata\", \".rsrc\", \".reloc\", \".bss\", \".tls\", \".debug\"\n",
        "]\n",
        "\n",
        "# normalize dll names lower-case for matching\n",
        "KNOWN_DLLS = [\n",
        "    \"kernel32.dll\", \"advapi32.dll\", \"user32.dll\", \"gdi32.dll\",\n",
        "    \"ntdll.dll\", \"ws2_32.dll\", \"wsock32.dll\", \"wininet.dll\"\n",
        "]\n",
        "\n",
        "SUSPICIOUS_APIS = [\n",
        "    \"VirtualAlloc\", \"VirtualAllocEx\", \"VirtualProtect\",\n",
        "    \"WriteProcessMemory\", \"CreateRemoteThread\", \"LoadLibrary\",\n",
        "    \"GetProcAddress\", \"WinExec\", \"ShellExecute\", \"URLDownloadToFile\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cMcfWEqpZ2g6"
      },
      "outputs": [],
      "source": [
        "def get_entropy(data):\n",
        "    if not data:\n",
        "        return 0.0\n",
        "    counter = Counter(data)\n",
        "    length = len(data)\n",
        "    entropy = 0.0\n",
        "    for count in counter.values():\n",
        "        p_x = count / length\n",
        "        entropy -= p_x * math.log2(p_x)\n",
        "    return entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ESm8SAqzZ3td"
      },
      "outputs": [],
      "source": [
        "def md5_file(path):\n",
        "    import hashlib\n",
        "    h = hashlib.md5()\n",
        "    with open(path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(8192), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H1wLxX8zZ4-c"
      },
      "outputs": [],
      "source": [
        "def safe_decode(b):\n",
        "    try:\n",
        "        return b.decode(errors=\"ignore\")\n",
        "    except:\n",
        "        return str(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RdlhxSkGZ903"
      },
      "outputs": [],
      "source": [
        "def extract_features(file_path, label):\n",
        "    feats = {}\n",
        "    try:\n",
        "        pe = pefile.PE(file_path, fast_load=True)\n",
        "        pe.parse_data_directories(directories=[\n",
        "            pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_IMPORT'],\n",
        "            pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_EXPORT'],\n",
        "            pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_RESOURCE'],\n",
        "            pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_TLS']\n",
        "        ])\n",
        "    except Exception as e:\n",
        "        print(f\"[!] Cannot parse PE {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        data = f.read()\n",
        "    feats[\"MD5\"] = md5_file(file_path)\n",
        "    feats[\"FileSize\"] = len(data)\n",
        "    feats[\"FileEntropy\"] = round(get_entropy(data), 3)\n",
        "\n",
        "    try:\n",
        "        fh = pe.FILE_HEADER\n",
        "        oh = pe.OPTIONAL_HEADER\n",
        "        feats[\"TimeDateStamp\"] = fh.TimeDateStamp\n",
        "        feats[\"Machine\"] = fh.Machine\n",
        "        feats[\"Characteristics\"] = fh.Characteristics\n",
        "        feats[\"NumberOfSections\"] = fh.NumberOfSections\n",
        "        feats[\"AddressOfEntryPoint\"] = oh.AddressOfEntryPoint\n",
        "        feats[\"SizeOfImage\"] = oh.SizeOfImage\n",
        "        feats[\"SizeOfHeaders\"] = oh.SizeOfHeaders\n",
        "        feats[\"Subsystem\"] = oh.Subsystem\n",
        "        feats[\"DllCharacteristics\"] = oh.DllCharacteristics\n",
        "        feats[\"LinkerVersion\"] = f\"{oh.MajorLinkerVersion}.{oh.MinorLinkerVersion}\"\n",
        "        feats[\"Checksum\"] = oh.CheckSum\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    feats[\"Has_TLS\"] = 1 if hasattr(pe, \"DIRECTORY_ENTRY_TLS\") else 0\n",
        "\n",
        "    # Section-level\n",
        "    section_map = {sec.Name.decode(errors=\"ignore\").rstrip(\"\\x00\"): sec for sec in pe.sections}\n",
        "    for s in KNOWN_SECTIONS:\n",
        "        key_presence = f\"sec_present_{s.strip('.')}\"\n",
        "        feats[key_presence] = 0\n",
        "        feats[f\"sec_entropy_{s.strip('.')}\"] = 0.0\n",
        "        feats[f\"sec_virtualsize_{s.strip('.')}\"] = 0\n",
        "        feats[f\"sec_rawsize_{s.strip('.')}\"] = 0\n",
        "        feats[f\"sec_ratio_{s.strip('.')}\"] = 0.0\n",
        "\n",
        "    for raw_name, sec in section_map.items():\n",
        "        name = raw_name if isinstance(raw_name, str) else raw_name.decode(errors=\"ignore\").rstrip(\"\\x00\")\n",
        "        lname = name.lower()\n",
        "        matched = None\n",
        "        for s in KNOWN_SECTIONS:\n",
        "            if lname == s or lname.startswith(s):\n",
        "                matched = s\n",
        "                break\n",
        "        if matched:\n",
        "            feats[f\"sec_present_{matched.strip('.')}\"] = 1\n",
        "            raw = sec.get_data()\n",
        "            ent = round(get_entropy(raw), 3)\n",
        "            feats[f\"sec_entropy_{matched.strip('.')}\"] = ent\n",
        "            feats[f\"sec_virtualsize_{matched.strip('.')}\"] = sec.Misc_VirtualSize\n",
        "            feats[f\"sec_rawsize_{matched.strip('.')}\"] = sec.SizeOfRawData\n",
        "            feats[f\"sec_ratio_{matched.strip('.')}\"] = round(sec.Misc_VirtualSize / sec.SizeOfRawData, 3) if sec.SizeOfRawData else 0.0\n",
        "\n",
        "    entropies, ratios = [], []\n",
        "    for sec in pe.sections:\n",
        "        try:\n",
        "            entropies.append(get_entropy(sec.get_data()))\n",
        "            if sec.SizeOfRawData:\n",
        "                ratios.append(sec.Misc_VirtualSize / sec.SizeOfRawData)\n",
        "        except:\n",
        "            pass\n",
        "    feats[\"mean_section_entropy\"] = round(sum(entropies)/len(entropies), 3) if entropies else 0.0\n",
        "    feats[\"mean_section_ratio\"] = round(sum(ratios)/len(ratios), 3) if ratios else 0.0\n",
        "\n",
        "    import_count, suspicious_api_count = 0, 0\n",
        "    dll_presence = {dll: 0 for dll in KNOWN_DLLS}\n",
        "    top_imports = []\n",
        "    try:\n",
        "        if hasattr(pe, \"DIRECTORY_ENTRY_IMPORT\"):\n",
        "            for entry in pe.DIRECTORY_ENTRY_IMPORT:\n",
        "                dllname = safe_decode(entry.dll).lower()\n",
        "                import_count += len(entry.imports)\n",
        "                for known in KNOWN_DLLS:\n",
        "                    if known in dllname:\n",
        "                        dll_presence[known] = 1\n",
        "                for imp in entry.imports:\n",
        "                    if imp.name:\n",
        "                        iname = imp.name.decode(errors=\"ignore\")\n",
        "                        top_imports.append(iname)\n",
        "                        for api in SUSPICIOUS_APIS:\n",
        "                            if api.lower() in iname.lower():\n",
        "                                suspicious_api_count += 1\n",
        "                    else:\n",
        "                        top_imports.append(str(imp.ordinal))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    feats[\"import_count\"] = import_count\n",
        "    feats[\"suspicious_api_count\"] = suspicious_api_count\n",
        "    for dll, val in dll_presence.items():\n",
        "        feats[f\"dll_{dll.replace('.', '_')}\"] = val\n",
        "\n",
        "    N = 10\n",
        "    for i in range(N):\n",
        "        feats[f\"import_{i}\"] = top_imports[i] if i < len(top_imports) else \"\"\n",
        "\n",
        "    export_count = 0\n",
        "    try:\n",
        "        if hasattr(pe, \"DIRECTORY_ENTRY_EXPORT\") and pe.DIRECTORY_ENTRY_EXPORT:\n",
        "            export_count = len(pe.DIRECTORY_ENTRY_EXPORT.symbols)\n",
        "    except:\n",
        "        pass\n",
        "    feats[\"export_count\"] = export_count\n",
        "\n",
        "    res_count, res_total_size = 0, 0\n",
        "    try:\n",
        "        if hasattr(pe, \"DIRECTORY_ENTRY_RESOURCE\"):\n",
        "            for res_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:\n",
        "                def traverse(node):\n",
        "                    nonlocal res_count, res_total_size\n",
        "                    if hasattr(node, 'directory'):\n",
        "                        for e in node.directory.entries:\n",
        "                            traverse(e)\n",
        "                    elif hasattr(node, 'data'):\n",
        "                        res_count += 1\n",
        "                        res_total_size += node.data.struct.Size\n",
        "                traverse(res_type)\n",
        "    except:\n",
        "        pass\n",
        "    feats[\"resource_count\"] = res_count\n",
        "    feats[\"resource_total_size\"] = res_total_size\n",
        "\n",
        "    printable_strings = []\n",
        "    try:\n",
        "        parts = data.split(b'\\x00')\n",
        "        for p in parts:\n",
        "            if len(p) >= 4:\n",
        "                try:\n",
        "                    s = p.decode('utf-8', errors='ignore')\n",
        "                    if any(c.isalnum() for c in s):\n",
        "                        printable_strings.append(s)\n",
        "                except:\n",
        "                    pass\n",
        "    except:\n",
        "        pass\n",
        "    feats[\"strings_count\"] = len(printable_strings)\n",
        "\n",
        "    suspicious_kw = [\"http://\", \"https://\", \"hkey_local_machine\", \"cmd.exe\", \"powershell\", \".exe\", \".dll\"]\n",
        "    feats[\"suspicious_string_count\"] = sum(1 for s in printable_strings if any(k in s.lower() for k in suspicious_kw))\n",
        "\n",
        "    feats[\"label\"] = label\n",
        "    return feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XQ_Fe2xoZvG6"
      },
      "outputs": [],
      "source": [
        "def scan_and_save(dataset_root, out_csv):\n",
        "    rows = []\n",
        "    for root, _, files in os.walk(dataset_root):\n",
        "        for fn in files:\n",
        "            if fn.lower().endswith((\".exe\", \".dll\")):\n",
        "                path = os.path.join(root, fn)\n",
        "                parts = root.split(os.sep)\n",
        "                if \"benign\" in root.lower():\n",
        "                    label = \"Benign\"\n",
        "                elif \"virus\" in root.lower():\n",
        "                    label = parts[-1].capitalize()\n",
        "                else:\n",
        "                    label = \"Unknown\"\n",
        "                feats = extract_features(path, label)\n",
        "                if feats:\n",
        "                    rows.append(feats)\n",
        "\n",
        "    if not rows:\n",
        "        print(\"No samples processed.\")\n",
        "        return\n",
        "\n",
        "    fieldnames = sorted(rows[0].keys())\n",
        "    with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as fout:\n",
        "        writer = csv.DictWriter(fout, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for r in rows:\n",
        "            for f in fieldnames:\n",
        "                if f not in r:\n",
        "                    r[f] = \"\"\n",
        "            writer.writerow(r)\n",
        "    print(f\"[+] Saved {len(rows)} samples to {out_csv}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Bf5ec-hYaAtL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[!] Cannot parse PE Dataset/Benign/Benign train/iissetup.exe: 'DOS Header magic not found.'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign train/nfsadmin.exe: 'DOS Header magic not found.'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign train/wpmmapi.exe: 'Invalid NT Headers signature. Probably a NE file'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign train/rpcinfo.exe: 'DOS Header magic not found.'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign train/pconfig.exe: 'Invalid NT Headers signature.'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign test/LockAppHost.exe: 'DOS Header magic not found.'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign test/BootExpCfg.exe: 'DOS Header magic not found.'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign test/pmsort.exe: 'Invalid e_lfanew value, probably not a PE file'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign test/pmgrant.exe: 'Invalid e_lfanew value, probably not a PE file'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign test/LogCollector.exe: 'DOS Header magic not found.'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign test/aspnetca.exe: 'DOS Header magic not found.'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign test/urlproxy.exe: 'Invalid NT Headers signature. Probably a NE file'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign test/newmail.exe: 'Invalid e_lfanew value, probably not a PE file'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign test/sysprep.exe: 'DOS Header magic not found.'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign test/ldifde.exe: 'DOS Header magic not found.'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign test/malias.exe: 'Invalid e_lfanew value, probably not a PE file'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign test/adaminstall.exe: 'DOS Header magic not found.'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign test/fsynonym.exe: 'Invalid e_lfanew value, probably not a PE file'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign test/SettingSyncHost.exe: 'DOS Header magic not found.'\n",
            "[!] Cannot parse PE Dataset/Benign/Benign test/evntwin.exe: 'DOS Header magic not found.'\n",
            "[+] Saved 9950 samples to DataAnalyzed/pe_features_multi.csv\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    dataset_dir = \"Dataset\"\n",
        "    output_file = \"DataAnalyzed/pe_features_multi.csv\"\n",
        "    scan_and_save(dataset_dir, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"DataAnalyzed/pe_features_multi.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9950 entries, 0 to 9949\n",
            "Data columns (total 98 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   AddressOfEntryPoint      9950 non-null   int64  \n",
            " 1   Characteristics          9950 non-null   int64  \n",
            " 2   Checksum                 9950 non-null   int64  \n",
            " 3   DllCharacteristics       9950 non-null   int64  \n",
            " 4   FileEntropy              9950 non-null   float64\n",
            " 5   FileSize                 9950 non-null   int64  \n",
            " 6   Has_TLS                  9950 non-null   int64  \n",
            " 7   LinkerVersion            9950 non-null   float64\n",
            " 8   MD5                      9950 non-null   object \n",
            " 9   Machine                  9950 non-null   int64  \n",
            " 10  NumberOfSections         9950 non-null   int64  \n",
            " 11  SizeOfHeaders            9950 non-null   int64  \n",
            " 12  SizeOfImage              9950 non-null   int64  \n",
            " 13  Subsystem                9950 non-null   int64  \n",
            " 14  TimeDateStamp            9950 non-null   int64  \n",
            " 15  dll_advapi32_dll         9950 non-null   int64  \n",
            " 16  dll_gdi32_dll            9950 non-null   int64  \n",
            " 17  dll_kernel32_dll         9950 non-null   int64  \n",
            " 18  dll_ntdll_dll            9950 non-null   int64  \n",
            " 19  dll_user32_dll           9950 non-null   int64  \n",
            " 20  dll_wininet_dll          9950 non-null   int64  \n",
            " 21  dll_ws2_32_dll           9950 non-null   int64  \n",
            " 22  dll_wsock32_dll          9950 non-null   int64  \n",
            " 23  export_count             9950 non-null   int64  \n",
            " 24  import_0                 9897 non-null   object \n",
            " 25  import_1                 9764 non-null   object \n",
            " 26  import_2                 9763 non-null   object \n",
            " 27  import_3                 9754 non-null   object \n",
            " 28  import_4                 9741 non-null   object \n",
            " 29  import_5                 9659 non-null   object \n",
            " 30  import_6                 9566 non-null   object \n",
            " 31  import_7                 9489 non-null   object \n",
            " 32  import_8                 9394 non-null   object \n",
            " 33  import_9                 9089 non-null   object \n",
            " 34  import_count             9950 non-null   int64  \n",
            " 35  label                    9950 non-null   object \n",
            " 36  mean_section_entropy     9950 non-null   float64\n",
            " 37  mean_section_ratio       9950 non-null   float64\n",
            " 38  resource_count           9950 non-null   int64  \n",
            " 39  resource_total_size      9950 non-null   int64  \n",
            " 40  sec_entropy_bss          9950 non-null   float64\n",
            " 41  sec_entropy_data         9950 non-null   float64\n",
            " 42  sec_entropy_debug        9950 non-null   float64\n",
            " 43  sec_entropy_edata        9950 non-null   float64\n",
            " 44  sec_entropy_idata        9950 non-null   float64\n",
            " 45  sec_entropy_pdata        9950 non-null   float64\n",
            " 46  sec_entropy_rdata        9950 non-null   float64\n",
            " 47  sec_entropy_reloc        9950 non-null   float64\n",
            " 48  sec_entropy_rsrc         9950 non-null   float64\n",
            " 49  sec_entropy_text         9950 non-null   float64\n",
            " 50  sec_entropy_tls          9950 non-null   float64\n",
            " 51  sec_present_bss          9950 non-null   int64  \n",
            " 52  sec_present_data         9950 non-null   int64  \n",
            " 53  sec_present_debug        9950 non-null   int64  \n",
            " 54  sec_present_edata        9950 non-null   int64  \n",
            " 55  sec_present_idata        9950 non-null   int64  \n",
            " 56  sec_present_pdata        9950 non-null   int64  \n",
            " 57  sec_present_rdata        9950 non-null   int64  \n",
            " 58  sec_present_reloc        9950 non-null   int64  \n",
            " 59  sec_present_rsrc         9950 non-null   int64  \n",
            " 60  sec_present_text         9950 non-null   int64  \n",
            " 61  sec_present_tls          9950 non-null   int64  \n",
            " 62  sec_ratio_bss            9950 non-null   float64\n",
            " 63  sec_ratio_data           9950 non-null   float64\n",
            " 64  sec_ratio_debug          9950 non-null   float64\n",
            " 65  sec_ratio_edata          9950 non-null   float64\n",
            " 66  sec_ratio_idata          9950 non-null   float64\n",
            " 67  sec_ratio_pdata          9950 non-null   float64\n",
            " 68  sec_ratio_rdata          9950 non-null   float64\n",
            " 69  sec_ratio_reloc          9950 non-null   float64\n",
            " 70  sec_ratio_rsrc           9950 non-null   float64\n",
            " 71  sec_ratio_text           9950 non-null   float64\n",
            " 72  sec_ratio_tls            9950 non-null   float64\n",
            " 73  sec_rawsize_bss          9950 non-null   int64  \n",
            " 74  sec_rawsize_data         9950 non-null   int64  \n",
            " 75  sec_rawsize_debug        9950 non-null   int64  \n",
            " 76  sec_rawsize_edata        9950 non-null   int64  \n",
            " 77  sec_rawsize_idata        9950 non-null   int64  \n",
            " 78  sec_rawsize_pdata        9950 non-null   int64  \n",
            " 79  sec_rawsize_rdata        9950 non-null   int64  \n",
            " 80  sec_rawsize_reloc        9950 non-null   int64  \n",
            " 81  sec_rawsize_rsrc         9950 non-null   int64  \n",
            " 82  sec_rawsize_text         9950 non-null   int64  \n",
            " 83  sec_rawsize_tls          9950 non-null   int64  \n",
            " 84  sec_virtualsize_bss      9950 non-null   int64  \n",
            " 85  sec_virtualsize_data     9950 non-null   int64  \n",
            " 86  sec_virtualsize_debug    9950 non-null   int64  \n",
            " 87  sec_virtualsize_edata    9950 non-null   int64  \n",
            " 88  sec_virtualsize_idata    9950 non-null   int64  \n",
            " 89  sec_virtualsize_pdata    9950 non-null   int64  \n",
            " 90  sec_virtualsize_rdata    9950 non-null   int64  \n",
            " 91  sec_virtualsize_reloc    9950 non-null   int64  \n",
            " 92  sec_virtualsize_rsrc     9950 non-null   int64  \n",
            " 93  sec_virtualsize_text     9950 non-null   int64  \n",
            " 94  sec_virtualsize_tls      9950 non-null   int64  \n",
            " 95  strings_count            9950 non-null   int64  \n",
            " 96  suspicious_api_count     9950 non-null   int64  \n",
            " 97  suspicious_string_count  9950 non-null   int64  \n",
            "dtypes: float64(26), int64(60), object(12)\n",
            "memory usage: 7.4+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(str(df.info()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
