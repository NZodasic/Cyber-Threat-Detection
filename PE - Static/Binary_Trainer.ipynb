{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from scipy import sparse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "4y2FsMLTHzMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "MKy80v6VH0x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "CSV_PATH = \"pe_features_multi.csv\"\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(\"Samples per class:\\n\", df['label'].value_counts())"
      ],
      "metadata": {
        "id": "yYrfnyLfIDHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle imports text\n",
        "import_cols = [c for c in df.columns if c.startswith(\"import_\")]\n",
        "if import_cols:\n",
        "    df['imports_text'] = df[import_cols].fillna(\"\").astype(str).apply(\n",
        "        lambda row: \" \".join([t for t in row if t and t != 'nan']), axis=1\n",
        "    )\n"
      ],
      "metadata": {
        "id": "7XpJrLwWIEwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unneeded\n",
        "drop_like = [c for c in df.columns if c.lower() in ('md5','filename','filepath','file_path')]\n",
        "df = df.drop(columns=[c for c in drop_like if c in df.columns])\n",
        "\n",
        "obj_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "for c in obj_cols:\n",
        "    if c not in ('imports_text', 'label'):\n",
        "        df = df.drop(columns=[c])"
      ],
      "metadata": {
        "id": "IqSKQr1PIF_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels (multi-class)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df['label'])\n",
        "print(\"Classes:\", le.classes_)\n",
        "df = df.drop(columns=['label'])"
      ],
      "metadata": {
        "id": "XsVi2OXNIGwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeric features\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "if 'imports_text' not in df.columns:\n",
        "    df['imports_text'] = \"\""
      ],
      "metadata": {
        "id": "swH7vJt8IIJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "MAX_IMPORT_FEATURES = 500\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', num_pipeline, numeric_cols),\n",
        "    ('imp', CountVectorizer(max_features=MAX_IMPORT_FEATURES, token_pattern=r\"(?u)\\b\\w+\\b\"), 'imports_text')\n",
        "], remainder='drop', sparse_threshold=0.3)"
      ],
      "metadata": {
        "id": "Eio95Z0pIJnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split\n",
        "X_train_df, X_test_df, y_train, y_test = train_test_split(\n",
        "    df, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "preprocessor.fit(X_train_df)\n",
        "X_train_trans = preprocessor.transform(X_train_df)\n",
        "X_test_trans  = preprocessor.transform(X_test_df)\n",
        "\n",
        "if sparse.issparse(X_train_trans):\n",
        "    X_train = X_train_trans.toarray()\n",
        "    X_test  = X_test_trans.toarray()\n",
        "else:\n",
        "    X_train = X_train_trans\n",
        "    X_test  = X_test_trans\n",
        "\n",
        "print(\"Feature matrix shape:\", X_train.shape)"
      ],
      "metadata": {
        "id": "HibcDN9YIKGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForest\n",
        "rf = RandomForestClassifier(n_estimators=300, n_jobs=-1, class_weight='balanced', random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "cm_rf = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm_rf, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title(\"RandomForest Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "print(\"=== RandomForest Report ===\")\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "\n",
        "joblib.dump(rf, \"rf_pe_model.joblib\")\n",
        "joblib.dump(preprocessor, \"preprocessor.joblib\")\n",
        "joblib.dump(le, \"label_encoder.joblib\")\n",
        "print(\"[+] Saved RandomForest model, preprocessor, and label encoder.\")"
      ],
      "metadata": {
        "id": "AeZ856SPILff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch MLP\n",
        "num_classes = len(le.classes_)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, out_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "AVAc7uV1ILPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(X_train.shape[1], num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "U7KpjT9SIes3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_t  = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t  = torch.tensor(y_test, dtype=torch.long)"
      ],
      "metadata": {
        "id": "YRQyUqp8IfhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_sample_count = np.bincount(y_train)\n",
        "weights = 1.0 / class_sample_count\n",
        "samples_weight = weights[y_train]\n",
        "samples_weight = torch.from_numpy(samples_weight.astype(np.float32))\n",
        "sampler = WeightedRandomSampler(samples_weight, num_samples=len(samples_weight), replacement=True)"
      ],
      "metadata": {
        "id": "CLMJiPAsIgjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=64, sampler=sampler)\n",
        "test_loader = DataLoader(TensorDataset(X_test_t, y_test_t), batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "Zej0okRuIhT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "history = {\"loss\": []}"
      ],
      "metadata": {
        "id": "CDgkgchBIinF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "    avg_loss = total_loss / len(train_loader.dataset)\n",
        "    history[\"loss\"].append(avg_loss)\n",
        "    print(f\"Epoch {epoch:02d} | loss={avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "uyH2wj_BHw02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "model.eval()\n",
        "preds = []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device)\n",
        "        out = model(xb)\n",
        "        pred = out.argmax(dim=1).cpu().numpy()\n",
        "        preds.extend(pred.tolist())\n",
        "\n",
        "cm_mlp = confusion_matrix(y_test, preds)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm_mlp, annot=True, fmt=\"d\", cmap=\"Oranges\", xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title(\"MLP Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "print(\"=== PyTorch MLP Report ===\")\n",
        "print(classification_report(y_test, preds, target_names=le.classes_))\n",
        "\n",
        "torch.save(model.state_dict(), \"pe_mlp.pt\")\n",
        "print(\"[+] Saved PyTorch model.\")\n"
      ],
      "metadata": {
        "id": "2c9Izmi-IjoR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}